{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naivebayes_TFonly",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHQ26pExH6GC"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('Data Komentar DL 900.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "bPAqxNnIwmnD",
        "outputId": "1f9d56e3-efe5-4812-e911-3059d6798d19"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KOMENTAR</th>\n",
              "      <th>SENTIMEN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bagus. Salah satu pendekatan antropologi diken...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Terimakasih, saya dapat informasi yg sangat be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Terima kasih mahasiswa perwakilan dari Indones...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bagus mas menteri, saya bangga</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ide sangat cemerlang n patut didukung oleh sem...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bagus sih mari dicoba\\\\t</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ayo sukseskan bersama kebijakan kampus merdeka...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>luar biasa cara respon rencana solusi pelaksan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Suka bgt sama mba no 3, mewakilkan para anak P...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ITUlah CARA yg paling baik n BERKWALITAS,  MAJ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            KOMENTAR  SENTIMEN\n",
              "0  Bagus. Salah satu pendekatan antropologi diken...         1\n",
              "1  Terimakasih, saya dapat informasi yg sangat be...         1\n",
              "2  Terima kasih mahasiswa perwakilan dari Indones...         1\n",
              "3                     bagus mas menteri, saya bangga         1\n",
              "4  ide sangat cemerlang n patut didukung oleh sem...         1\n",
              "5                           bagus sih mari dicoba\\\\t         1\n",
              "6  ayo sukseskan bersama kebijakan kampus merdeka...         1\n",
              "7  luar biasa cara respon rencana solusi pelaksan...         1\n",
              "8  Suka bgt sama mba no 3, mewakilkan para anak P...         1\n",
              "9  ITUlah CARA yg paling baik n BERKWALITAS,  MAJ...         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxe7lLmgsp8j"
      },
      "source": [
        "**TEXT PRERPOCESSING**\r\n",
        "\r\n",
        "this process consists of :\r\n",
        "1. Case Folding\r\n",
        "2. Tokenization\r\n",
        "3. Perbaikan Kata Tidak Baku\r\n",
        "3. Stopwords Removal\r\n",
        "4. Stemming\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s71PKf6cym_n",
        "outputId": "7624957a-6b6a-42b4-8439-bcd1dea512a6"
      },
      "source": [
        "#-- CASE FOLDING --\n",
        "import string\n",
        "import re #regex library\n",
        "\n",
        "data['KOMENTAR'] = data['KOMENTAR'].str.lower()\n",
        "\n",
        "def casef(text):\n",
        "    # remove tab, new line, ans back slice\n",
        "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
        "    # remove non ASCII (emoticon, chinese word, .etc)\n",
        "    text = text.encode('ascii', 'replace').decode('ascii')\n",
        "    # remove mention, link, hashtag\n",
        "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
        "    # remove incomplete URL\n",
        "    text= text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
        "    #remove number\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    #remove punctuation/tanda baca\n",
        "    text = text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "    #remove whitespace leading & trailing/ spasi\n",
        "    text = text.strip()\n",
        "    #remove multiple whitespace into single whitespace\n",
        "    text = re.sub('\\s+',' ',text)\n",
        "    return text\n",
        "\n",
        "data['casefold'] = data['KOMENTAR'].apply(casef)\n",
        "hasil_casefolding= data['casefold']\n",
        "hasil_casefolding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      bagus salah satu pendekatan antropologi dikena...\n",
              "1      terimakasih saya dapat informasi yg sangat ber...\n",
              "2      terima kasih mahasiswa perwakilan dari indones...\n",
              "3                          bagus mas menteri saya bangga\n",
              "4      ide sangat cemerlang n patut didukung oleh sem...\n",
              "                             ...                        \n",
              "995    klo negara mau harusnya pendidikan ditegakkan ...\n",
              "996                   sayang sekali belum ada pemerataan\n",
              "997    kampusnya banyak lapangan kerjanya dikit meman...\n",
              "998    saya pesimis dengan mental birokrasi skrg untu...\n",
              "999    risetnya ga bisa asal harus kualitas terbaik h...\n",
              "Name: casefold, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M4roXI8y9tU",
        "outputId": "9f4d7fc4-99aa-4d83-c3af-26020efcee94"
      },
      "source": [
        "# ------ Tokenizing ---------\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# import word_tokenize & FreqDist from NLTK\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "# NLTK word tokenize \n",
        "def word_tokenize_wrapper(text):\n",
        "  return word_tokenize(text)\n",
        "\n",
        "data['komen_tokens'] = data['casefold'].apply(word_tokenize_wrapper)\n",
        "\n",
        "print('Tokenizing Result : \\n') \n",
        "print(data['komen_tokens'].head())\n",
        "print('\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Tokenizing Result : \n",
            "\n",
            "0    [bagus, salah, satu, pendekatan, antropologi, ...\n",
            "1    [terimakasih, saya, dapat, informasi, yg, sang...\n",
            "2    [terima, kasih, mahasiswa, perwakilan, dari, i...\n",
            "3                  [bagus, mas, menteri, saya, bangga]\n",
            "4    [ide, sangat, cemerlang, n, patut, didukung, o...\n",
            "Name: komen_tokens, dtype: object\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PQdivmLG_mk",
        "outputId": "0ae747c9-a02a-4446-e44c-28c93247158a"
      },
      "source": [
        "#-- PERBAIKAN KATA TIDAK BAKU --\r\n",
        "\r\n",
        "normalized_word = pd.read_excel(\"kamus perbaikan kata.xlsx\")\r\n",
        "\r\n",
        "normalized_word_dict = {}\r\n",
        "\r\n",
        "for index, row in normalized_word.iterrows():\r\n",
        "    if row[0] not in normalized_word_dict:\r\n",
        "        normalized_word_dict[row[0]] = row[1] \r\n",
        "\r\n",
        "def normalized_term(document):\r\n",
        "    return [normalized_word_dict[term] if term in normalized_word_dict else term for term in document]\r\n",
        "\r\n",
        "data['komen_perbaikan'] = data['komen_tokens'].apply(normalized_term)\r\n",
        "\r\n",
        "data['komen_perbaikan'].tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "990    [magang, kelamaan, membuat, stres, juga, perus...\n",
              "991    [saya, pesimis, dengan, mental, birokrasi, sek...\n",
              "992    [kalau, cuma, pak, nadiem, saja, yang, revolus...\n",
              "993    [harus, bagaimana, dan, tempat, magangnya, jug...\n",
              "994    [kalau, untuk, yang, kuliah, sambil, kerja, ba...\n",
              "995    [kalau, negara, mau, harusnya, pendidikan, dit...\n",
              "996             [sayang, sekali, belum, ada, pemerataan]\n",
              "997    [kampusnya, banyak, lapangan, kerjanya, sediki...\n",
              "998    [saya, pesimis, dengan, mental, birokrasi, sek...\n",
              "999    [risetnya, tidak, bisa, asal, harus, kualitas,...\n",
              "Name: komen_perbaikan, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ETuuWLzCpG",
        "outputId": "b8912aec-b282-4dd2-8199-3b98b63c6a8e"
      },
      "source": [
        "#-- STOPWORDS REMOVAL --\n",
        "list_stopwords = {\"adalah\",\"akan\",\"akhir\",\"aku\",\"saya\",\"antara\",\"antaranya\",\"apabila\",\"atau\",\"bahwa\",\"bahwasannya\",\"berikut\",\"berkata\",\"berupa\",\"dan\",\"dalam\",\"dapat\",\"dari\",\"demikian\",\"dengan\",\"di\",\"dia\",\"beliau\",\"mas\",\"pak\",\"diri\",\"dirinya\",\"guna\",\"hal\",\"hingga\",\"ia\",\"ialah\",\"ibarat\",\"ibaratnya\",\"ibu\",\"ingin\",\"inginkan\",\"ini\",\"itu\",\"jadi\",\"kami\",\"kalian\",\"kamu\",\"kan\",\"karena\",\"kini\",\"lalu\",\"kita\",\"maka\",\"mereka\",\"merupakan\",\"misal\",\"misalkan\",\"misalnya\",\"pertama\",\"orang\",\"pada\",\"nya\",\"saat\",\"sendiri\",\"sini\",\"yaitu\",\"yang\",\"kalau\",\"jika\",\"untuk\",\"secara\",\"sedangkan\",\"luar\",\"alangkah\",\"wkkk\",\n",
        "                  \"wkwkw\",\"wkwkwkw\",\"wk\",\"wkkw\"}\n",
        "\n",
        "list_stopwords = set(list_stopwords)\n",
        "\n",
        "#remove stopword pada list token\n",
        "def stopwords_removal(words):\n",
        "    return [word for word in words if word not in list_stopwords]\n",
        "\n",
        "data['komen_filtered'] = data['komen_perbaikan'].apply(stopwords_removal) \n",
        "\n",
        "print(data['komen_filtered'].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    [bagus, salah, satu, pendekatan, antropologi, ...\n",
            "1    [terimakasih, informasi, sangat, berguna, memo...\n",
            "2    [terima, kasih, mahasiswa, perwakilan, indones...\n",
            "3                             [bagus, menteri, bangga]\n",
            "4    [ide, sangat, cemerlang, patut, didukung, oleh...\n",
            "Name: komen_filtered, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZjFdj2Xz0Es",
        "outputId": "77e3f74a-3d1d-49dd-8c38-7f0da17708b8"
      },
      "source": [
        "pip install Sastrawi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5akBO9ahI6xX",
        "outputId": "7373cae1-52ea-4371-ea57-a6a622f45b12"
      },
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\r\n",
        "# create stemmer\r\n",
        "factory = StemmerFactory()\r\n",
        "stemmer = factory.create_stemmer()\r\n",
        "\r\n",
        "# stemmed\r\n",
        "def stemmed_wrapper(term):\r\n",
        "    return stemmer.stem(term)\r\n",
        "\r\n",
        "term_dict = {}\r\n",
        "for document in data['komen_filtered']:\r\n",
        "    for term in document:\r\n",
        "        if term not in term_dict:\r\n",
        "            term_dict[term] = ' '\r\n",
        "\r\n",
        "for term in term_dict:\r\n",
        "    term_dict[term] = stemmed_wrapper(term)\r\n",
        "\r\n",
        "# apply stemmed term to dataframe\r\n",
        "def get_stemmed_term(document):\r\n",
        "    return [term_dict[term] for term in document]\r\n",
        "\r\n",
        "data['komen_stemmed'] = data['komen_filtered'].apply(get_stemmed_term)\r\n",
        "print(data['komen_stemmed'].tail(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "990    [magang, lama, buat, stres, juga, usaha, mana,...\n",
            "991        [pesimis, mental, birokrasi, sekarang, wujud]\n",
            "992    [cuma, nadiem, saja, revolusioner, tapi, bawah...\n",
            "993      [harus, bagaimana, tempat, magang, juga, susah]\n",
            "994    [kuliah, sambil, kerja, bagaimana, tinggal, do...\n",
            "995    [negara, mau, harus, didik, tegak, wilayah, lu...\n",
            "996                 [sayang, sekali, belum, ada, perata]\n",
            "997    [kampus, banyak, lapang, kerja, sedikit, meman...\n",
            "998        [pesimis, mental, birokrasi, sekarang, wujud]\n",
            "999    [riset, tidak, bisa, asal, harus, kualitas, ba...\n",
            "Name: komen_stemmed, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SiwhwJP4gy1",
        "outputId": "066bea6d-0c8e-4d12-ff72-264b49c214a1"
      },
      "source": [
        "#install scikit-learn library\r\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJNzU8-T6Y7V"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5isbePL6tTZW"
      },
      "source": [
        "**USING ORDINARY TERM WEIGHTING (TF-only)**\r\n",
        "\r\n",
        "in this step the term weighting is just identify biner-weighting (like yes or no) about term in the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meYsQRbA60NE"
      },
      "source": [
        "max_features = 1000\n",
        "databaru= data['komen_stemmed'].astype(str)\n",
        "\n",
        "#menambahkan ngram=(1,2) dst kalo mau pake pemisahan per 2 kata atau lebih\n",
        "cvect = CountVectorizer(max_features=max_features, ngram_range=(1,3), binary=True)\n",
        "TF_vector = cvect.fit_transform(databaru)\n",
        "\n",
        "# hitung TF\n",
        "tfidf_matt = cvect.fit_transform(databaru).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX1ompdB_27u"
      },
      "source": [
        "X= tfidf_matt\n",
        "Y= data['SENTIMEN']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-iu9uL1wT_r"
      },
      "source": [
        "**SPLITTING DATA**\r\n",
        "\r\n",
        "total data is 1000 sentiments consist of positive and negative with 50:50 portion. data splits is consist of 900 data train and 100 data test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdblkP9R_VWn"
      },
      "source": [
        "#splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.10,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa5MJZjfwy73"
      },
      "source": [
        "**CLASSIFICATION PROCESS**\r\n",
        "in this project the classification is using Naive Bayes Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3u_jQaRAesD",
        "outputId": "58d7cf6c-120f-4754-d54b-4f2d466f0c60"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "clasfc= BernoulliNB()\n",
        "cl= clasfc.fit(X_train,Y_train)\n",
        "Y_pred= cl.predict(X_test)\n",
        "Y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMekl1AgxAXK"
      },
      "source": [
        "**EVALUATION**\r\n",
        "\r\n",
        "the evaluation method is confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9JD6nTuBEJ5",
        "outputId": "72fd7764-916c-4a6f-a12f-2dfcd5f22dba"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(Y_test,Y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[45,  3],\n",
              "       [ 6, 46]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml3GD0nyI_eg"
      },
      "source": [
        "TP = 46\r\n",
        "TN = 45\r\n",
        "FP = 3\r\n",
        "FN = 6"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOYYGW56BI1j",
        "outputId": "ecf0ff62-ce92-49de-8eee-a325560a3b05"
      },
      "source": [
        "accuracy= (TN+TP)/(TN+TP+FN+FP)\n",
        "accuracy"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C7AcZJGJEK3",
        "outputId": "18b24979-973e-4772-c29c-9f845f278b02"
      },
      "source": [
        "precision= TP/(TP+FP)\r\n",
        "precision"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9387755102040817"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkIoXF6aJFfg",
        "outputId": "2e51803a-6154-449e-c3fd-6f030ff89b89"
      },
      "source": [
        "recall= TP/(TP+FN)\r\n",
        "recall"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8846153846153846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pyZnoaYJG5Z",
        "outputId": "f9567949-2e51-48b7-9ddf-85e4cf95cc78"
      },
      "source": [
        "f1meas= (2*precision*recall)/(precision+recall)\r\n",
        "f1meas"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9108910891089108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}